{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af68111f-7532-4b92-9f8c-3b7c7959ba46",
   "metadata": {},
   "source": [
    "# Basic use of fundamental functions\n",
    "\n",
    "$\\newcommand{\\bDelta}{\\boldsymbol{\\Delta}}\n",
    "\\newcommand{\\bmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\bnu}{\\boldsymbol{\\nu}}\n",
    "\\newcommand{\\bsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\bSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\btheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\blambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\Xs}{X_{\\mathrm{s}}}\n",
    "\\newcommand{\\Xt}{X_{\\mathrm{t}}}\n",
    "\\newcommand{\\gs}{\\mathbf{g}_{\\mathrm{s}}}\n",
    "\\newcommand{\\gt}{\\mathbf{g}_{\\mathrm{t}}}\n",
    "\\newcommand{\\Hs}{\\mathbf{H}_{\\mathrm{s}}}\n",
    "\\newcommand{\\Ht}{\\mathbf{H}_{\\mathrm{t}}}\n",
    "\\newcommand{\\caL}{\\mathcal{L}}\n",
    "\\newcommand{\\bD}{\\mathbf{D}}\n",
    "\\newcommand{\\be}{\\mathbf{e}}\n",
    "\\newcommand{\\bg}{\\mathbf{g}}\n",
    "\\newcommand{\\bG}{\\mathbf{G}}\n",
    "\\newcommand{\\bH}{\\mathbf{H}}\n",
    "\\newcommand{\\bI}{\\mathbf{I}}\n",
    "\\newcommand{\\bJ}{\\mathbf{J}}\n",
    "\\newcommand{\\bK}{\\mathbf{K}}\n",
    "\\newcommand{\\bM}{\\mathbf{M}}\n",
    "\\newcommand{\\bP}{\\mathbf{P}}\n",
    "\\newcommand{\\bT}{\\mathbf{T}}\n",
    "\\newcommand{\\bU}{\\mathbf{U}}\n",
    "\\newcommand{\\bu}{\\mathbf{u}}\n",
    "\\newcommand{\\bv}{\\mathbf{v}}\n",
    "\\newcommand{\\bLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\bfeta}{\\boldsymbol{\\eta}}$<!--\n",
    "-->In this example, we show how to use the functions computing $\\bar{\\bH}$, $\\bar{\\bg}$, $\\bD$ and $\\bfeta^*$, where the chosen direction $\\bu$ is the opposite of the gradient: $\\bu := - \\bg$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5faf944-24a6-425c-aed3-cd124d2b401f",
   "metadata": {},
   "source": [
    "## Short reminder\n",
    "\n",
    "We consider a vector of parameters $\\btheta \\in \\mathbb{R}^P$. We represent this vector by\n",
    "a tuple of $S$ subsets (or groups) of parameters $(\\bT_1, \\cdots, \\bT_S)$. This tuple can be seen\n",
    "as a partition of the set of the indices $\\{1, \\cdots, P\\}$ of the vector $\\btheta$,\n",
    "so that each parameter $\\theta_p$ belongs to exactly one subset (or group) $\\bT_s$.\n",
    "We assume that $S \\ll P$.\n",
    "\n",
    "The goal consists in finding a vector $\\bfeta \\in \\mathbb{R}^S$ of learning rates,\n",
    "where each coordinate $\\eta_s$ is the learning rate corresponding to a subset $\\bT_s$.\n",
    "At each training step $t$, given a proposition of direction of descent $\\bu_t$, we aim to build the\n",
    "$\\bfeta_t$ maximizing the loss decrease. To do so, we take into account second- and third-order information.\n",
    "\n",
    "Therefore, we define:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{\\bH}_t = \\bI_{S:P} \\bU_t \\bH_t \\bU_t \\bI_{P:S} , \\qquad\n",
    "\\bar{\\bg}_t = \\bI_{S:P} \\bU_t \\bg_t , \\qquad\n",
    "\\bD_t = \\mathrm{Diag}(|\\bD^{(3)}_{\\btheta_t}(\\bu_t)|^{1/3}_{iii} : i \\in \\{1, \\cdots, S\\}) ,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\bg_t$ is the gradient of the loss at $\\btheta_t$ and $\\bH_t$ is its Hessian.\n",
    "Also, $\\bU_t = \\mathrm{Diag}(\\bu_t)$, $\\bI_{S:P}$ is the partition matrix: $(\\bI_{S:P})_{sp} = 1$ iff $\\theta_p \\in \\bT_s$ else $0$, \n",
    "$\\bI_{P:S} = \\bI_{S:P}^T$. Note that: $\\bar{\\bH}_t \\in \\mathbb{R}^{S \\times S}$, $\\bar{\\bg}_t \\in \\mathbb{R}^{S}$, $\\bD_t \\in \\mathbb{R}^{S \\times S}$.\n",
    "\n",
    "The training step of our method is: $\\btheta_{t + 1} = \\btheta_t - \\bU_t \\bI_{P:S} \\bfeta_t^*$, where\n",
    "$\\bfeta_t^*$ is the solution of largest norm $\\|\\bD_t \\bfeta\\|$ of the equation:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bfeta &= \\left(\\bar{\\bH}_t + \\frac{\\lambda_{\\mathrm{int}}}{2} \\|\\bD_t \\bfeta\\| \\bD_t^2\\right)^{-1}\\bar{\\bg}_t ,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\lambda_{\\mathrm{int}}$ is the internal damping, which is a hyperparameter to set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07194964-f12c-43a3-8d41-12d667b4bd39",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "We build a small dataset and a small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae0dd1c-2f9f-4753-9b34-48b54c8a6569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolinski/miniconda3/envs/pytorch/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from grnewt import compute_Hg, nesterov_lrs, fullbatch_gradient\n",
    "from grnewt import partition as build_partition\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5e8516-3a78-47a8-a3ab-cf62c8a08511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dummy regression dataset\n",
    "\n",
    "size_in = 5\n",
    "size_out = 4\n",
    "batch_size = 10\n",
    "\n",
    "data_in = torch.randn(batch_size, size_in)\n",
    "data_tar = torch.randn(batch_size, size_out)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(data_in, data_tar)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96567dc4-cc24-43d4-bdb1-7658d3d7fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simple model\n",
    "\n",
    "size_hidden = 6\n",
    "act_function_cl = torch.nn.Tanh\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.hidden_layer = torch.nn.Linear(size_in, size_hidden)\n",
    "        self.activation = act_function_cl()\n",
    "        self.out_layer = torch.nn.Linear(size_hidden, size_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.activation(x)\n",
    "        return self.out_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbea0763-9fda-443a-b5b0-11d132d00280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc94ac-24b1-46f2-9659-c4daf4620dcc",
   "metadata": {},
   "source": [
    "## Build the partition\n",
    "\n",
    "We build the partition of the parameters, which can be:\n",
    " * `canonical`: one tensor per subset;\n",
    " * `trivial`: all the parameters in the same subset;\n",
    " * `wb`: all the weights in one subset, all the biases in another one, and all the remaining parameters in a third one if necessary;\n",
    " * any custom partition.\n",
    "\n",
    "We build also some constants useful for the subsequent computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f29ebd9d-15ff-4ba0-9975-4fb496545afa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition with 4 subset(s).\n",
      "Subset #0 (size = 1):\n",
      "    hidden_layer.weight\n",
      "Subset #1 (size = 1):\n",
      "    hidden_layer.bias\n",
      "Subset #2 (size = 1):\n",
      "    out_layer.weight\n",
      "Subset #3 (size = 1):\n",
      "    out_layer.bias\n"
     ]
    }
   ],
   "source": [
    "# List of parameters\n",
    "tup_params = list(model.parameters())\n",
    "\n",
    "# Partition of the parameters\n",
    "param_groups, name_groups = build_partition.canonical(model) # canonical, trivial, wb\n",
    "nb_groups = len(name_groups)\n",
    "\n",
    "# List of sizes of each subset\n",
    "group_sizes = [len(pgroup['params']) for pgroup in param_groups]\n",
    "\n",
    "# List of starting index and ending index of each subset\n",
    "group_indices = [0] + list(np.cumsum(group_sizes))\n",
    "\n",
    "# Show the partition\n",
    "print(f'Partition with {nb_groups} subset(s).')\n",
    "for idx, ngroup in enumerate(name_groups):\n",
    "    print(f'Subset #{idx} (size = {len(ngroup)}):')\n",
    "    for name in ngroup:\n",
    "        print(f'    {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea60c6-90d6-453b-964b-935f01d10d20",
   "metadata": {},
   "source": [
    "## Computation of $\\bar{\\bH}$, $\\bar{\\bg}$ and $\\bD$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4eac76-69a6-4201-8236-25d7c606546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build losses\n",
    "\n",
    "#loss_fn = torch.nn.MSELoss()    # order3\n",
    "loss_fn = lambda x, y: (x - y).pow(2).mean().sqrt()\n",
    "full_loss = lambda x, y: loss_fn(model(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f869ddf5-6132-4400-af4b-42f7752f7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = fullbatch_gradient(model, loss_fn, tup_params, data_loader, batch_size)\n",
    "direction = tuple(-grad for grad in gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62c104e8-8dae-411c-bd31-e961467dccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, g, order3 = compute_Hg(tup_params, full_loss, data_in, data_tar, direction, \n",
    "           param_groups = param_groups, group_sizes = group_sizes, group_indices = group_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dd94154-42d1-448f-ac04-8d6e0c0ace8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, -0.18, '$\\\\mathbf{D}$')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, width_ratios = [1/nb_groups, 1, 1])\n",
    "\n",
    "ticks = list(range(nb_groups))\n",
    "\n",
    "gmax = g.abs().max()\n",
    "ax[0].matshow(g.unsqueeze(1), cmap = 'seismic', vmin = -gmax, vmax = gmax)\n",
    "ax[0].tick_params(bottom = False)\n",
    "ax[0].set_xticks([0])\n",
    "ax[0].set_xticklabels([0])\n",
    "ax[0].set_yticks(ticks)\n",
    "ax[0].set_yticklabels(ticks)\n",
    "ax[0].set_title(r'$\\bar{\\mathbf{g}}$', y = -.16)\n",
    "\n",
    "Hmax = H.abs().max()\n",
    "ax[1].matshow(H, cmap = 'seismic', vmin = -Hmax, vmax = Hmax)\n",
    "ax[1].tick_params(bottom = False)\n",
    "ax[1].set_xticks(ticks)\n",
    "ax[1].set_xticklabels(ticks)\n",
    "ax[1].set_yticks(ticks)\n",
    "ax[1].set_yticklabels(ticks)\n",
    "ax[1].set_title(r'$\\bar{\\mathbf{H}}$', y = -.18)\n",
    "\n",
    "regul = order3.abs().pow(2/3)\n",
    "regul_max = regul.max()\n",
    "ax[2].matshow(regul.diag(), cmap = 'seismic', vmin = -regul_max, vmax = regul_max)\n",
    "ax[2].tick_params(bottom = False)\n",
    "ax[2].set_xticks(ticks)\n",
    "ax[2].set_xticklabels(ticks)\n",
    "ax[2].set_yticks(ticks)\n",
    "ax[2].set_yticklabels(ticks)\n",
    "ax[2].set_title(r'$\\mathbf{D}$', y = -.18)\n",
    "\n",
    "#plt.suptitle('Summaries of derivatives at orders 1, 2, 3', y = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fe0e8-fc4f-4771-89f1-fb48a69eb927",
   "metadata": {},
   "source": [
    "## Computation of $\\bfeta^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900e3a15-0ef1-4a97-bf88-1f163ed0b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_int = 1.\n",
    "lrs, r_root, r_converged = nesterov_lrs(H, g, order3, damping_int = damping_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa77eadb-9596-4a3a-bed5-e7c11a10a4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.8856, -2.5241, -3.2933, -2.2851])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba4942-d0f4-4760-b18e-7b4720ee89f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
